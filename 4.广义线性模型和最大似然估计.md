# 1. 似然函数

所谓的似然函数，就是在已经知道采样数据的分布情况下，去==估计其分布函数的参数==是什么

比如，伯努利分布。一个无限大，有无穷多球的袋子，里面有若干个0号球和若干个1号球，对于一个0-1分布来说，抽到0球和抽到1球的概率分别是：

| X      | 0        | 1          |
| ------ | -------- | ---------- |
| P{X=K} | $\theta$ | $1-\theta$ |

若我们已经抽了5个球，其中3个1球和2个0球，我们可以得到这样的一个似然函数
$$
\Large L(\theta)=\theta^3(1-\theta^2)
$$
最大似然估计的思想在于，我们认为当似然函数最大时，得到的参数是分布的参数的概率最大
$$
\Large L'(\theta)=0\to\theta=\frac{2}{5}
$$
是函数$L(\theta)$的最大值

==但要注意的是：要区分样本总体是连续型还是非连续型==

对于连续型总体来说，其似然函数为概率密度的连乘：
$$
\Large L(\theta)=L(X_1,X_2,...X_n;\ \theta)=\prod f(X,\ \theta)
$$
而对于非连续型总体来说，其似然函数为概率分布的连乘（如伯努利的例子）：
$$
\Large L(\theta)=L(X_1,X_2,...X_n;\ \theta)=\prod p(X,\ \theta)
$$
对于==离散样本和连续样本的主要区别在于==我们对样本分布的建模方式，我们对样本的分布的预计，是离散的分布函数（如：伯努利分布）还是连续的分布（如：高斯分布），而不在于采样点之间的连续性。

# 2. 损失函数

对于所有的算法模型，都预设了独立同分布的前提条件，而不同的分布，决定了模型的输出项

当认为分布是高斯分布的时候，高斯分布的分布范围是整个实数域，那输出也是整个实数域，当认为分布是伯努利分布的时候，则分布范围就是0-1, 等等。下面从噪声分布的假设来解读损失函数。

## 2.1 高斯分布

一般，我们将线性回归问题视为高斯分布的情况。

当我们认为噪声以高斯分布的形式出现的时候，我们可以得到这样的结论：
$$
\Large y=g(x)+\epsilon, \ \ \ \epsilon\sim N(0, \sigma^2)
$$
（注意：这个噪声项必然是均值为0的，否则这个数据都发生偏移了。）
$$
\Large \epsilon(x)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp(-\frac{x^2}{\sigma^2})
$$
我们知道，高斯分布的对称轴位置概率最大，均值为0，对称轴在原点。因为观测噪声是符合高斯分布的，那么==残差也是符合高斯分布的==，于是通过给定的x观测到特定y的似然，就是残差的概率:==（没懂为什么）==
$$
\Large f(y_i|x_i)= \epsilon[y_i-g(x_i)]=\frac{1}{\sqrt{2\pi\sigma^2}}\exp[{-\frac{1}{2\sigma^2}(y_i-g(x_i))^2}]
$$


其中$\sigma$为噪声参数，与模型无关。又由于观测是独立同分布的，联合概率
$$
\begin{align*}
&\Large P(Y|X)=\prod_{i=1}^n f(y_i|x_i, \ \sigma^2)=\prod \frac{1}{\sqrt{2\pi\sigma^2}}\exp[{-\frac{1}{2\sigma^2}(y_i-g(x_i))^2}]\\
&\Large 最大似然估计\\
&\Large \to \max \ [\ln f(Y|X)]=\max \sum \ln(\frac{1}{\sqrt{2\pi\sigma^2}})+[{-\frac{1}{2\sigma^2}(y_i-g(x_i))^2}]\\
&\Large 其中\sigma与模型无关，故而不影响最大值\\
&\Large \max \sum-(y_i-g(x_i))^2 \to\max \ [\ln f(Y|X)] \\
&\Large 求最大值，就是求负数的最小值\\
&\color{red}\Large \min \sum (y_i-g(x_i))^2 \color{}\to \Large \max \sum-(y_i-g(x_i))^2 \to\max \ [\ln f(Y|X)]
\end{align*}
$$

其中$X=[x_i], Y=[y_i]$

## 2.2 伯努利分布

一般我们将二分类问题，认为是伯努利分布的情况。