# 1. 概念

一维搜索是在一个给定的函数f(x)中，寻找极值或者最值的过程

# 2. 试探法

此方法是用在单峰函数上进行的，

## 2.1. 进退法

在一个多峰函数中，通过进退法确定波谷区间，在波谷区间里面搜索极小值点（最小值点）

**进退法**用来寻找波谷区间（注意这是一个函数的波谷，离散数据不能用这个方法）

![img](./doc\1703564654535-7e61fdac-b3d9-410b-9a43-8751084ddb86.png)

算法的思路

![img](./doc\1703565152292-e57e608b-447e-495e-b223-d0d5f04fcffc.png)

```python
#  确定单峰区间
def successFailMethod(x1, h, func):  # x1为初始位置，h为步进长度
    f1 = func(x1)
    x2 = x1 + h
    f2 = func(x2)
    if f2 < f1:
        while True:
            x3 = x2 + h
            f3 = func(x3)
            if f3 < f2:
                x2 = x3
                f2 = f3
            else:
                break
        return [x1, x3]
    else:
        while True:
            x3 = x1 - h
            f3 = func(x3)
            if f3 < f1:
                x1 = x3
                f1 = f3
            else:
                break
        return [x3, x2]
```

<img src="doc/1703567256190-0d16e372-ede5-426e-bd3f-f152fa5c2ddf-17035785013465.png" alt="img" style="zoom:50%;" />

<img src="https://cdn.nlark.com/yuque/0/2023/png/1606105/1703567313776-c197a679-fe37-4a07-bed5-ebc5576c1579.png" alt="img" style="zoom:50%;" />

## 2.2. 确定极小值点

已知多峰函数的单峰区间，或者单峰函数即可用**试探法**确定极小值点（最小值点）

### 2.2.1. 黄金分割法

#### 2.2.1.1基本思路

在区间$[a_k, b_k]$， 尝试点为$\lambda_k=\alpha_k+(1-\tau)(b_k - a_k)$，$u_k=\alpha_k+\tau(b_k-\alpha_k)$，

![image-20231226163550950](doc/image-20231226163550950.png)

如果$f(\lambda_k)<f(\mu_k)$则极小值（最小值）一定在$[\alpha_k, \ \mu_k]$上，不可能在$[\mu_k, \ \beta_k]$上，则

我们更新边界：$f(\lambda_k)<f(\mu_k), \ \to \alpha_{k+1}=\alpha_k, \ \beta_{k+1}= \mu_k$

![image-20231226163634985](doc/image-20231226163634985.png)

如果$f(\lambda_k)>f(\mu_k)$则极小值（最小值）一定在$[\lambda_k, \ \beta_k]$上，不可能在$[\alpha_k, \ \mu_k]$上，则

我们更新边界：$f(\lambda_k)>f(\mu_k), \ \to \alpha_{k+1}=\lambda_k, \ \beta_{k+1}= \beta_k$



#### 2.2.2.2 $\tau$的取值

黄金分割法，为了减少计算过程更新的，我们会利用上次计算的结果。

![image-20231226163550950](doc/image-20231226163550950.png)

在这个例子中，$\beta_k =\mu_k$, 可以让新的$\mu_{k+1}=\lambda_k$，探索极值点是否在$[\alpha_k, \ \lambda_k]$上

为了实现这一点：
$$
\begin{align*}
&\Large \mu_{k+1}=\alpha_{k+1}+\tau(b_{k+1}-\alpha_{k+1})\\
&\Large 因为\alpha_{k+1}=\alpha_k,\beta_{k+1}=\mu_k\\
&\Large  \mu_{k+1}=\alpha_{k+1}+\tau(b_{k+1}-\alpha_{k+1})\\
&\Large \ \ \ \ \ \ \ \  =\alpha_k+\tau(\mu_k-\alpha_k)\\
&\Large \ \ \ \ \ \ \ \  = \alpha_k+\tau[a_k+\tau(\beta_k-\alpha_k)-\alpha_k]\\
&\Large \ \ \ \ \ \ \ \  =\alpha_k+\tau^2(\beta_k-\alpha_k)\\
&\Large \mu_{k+1}=\alpha_k+\tau^2(\beta_k-\alpha_k)=\lambda_k=\lambda_k+(1-\tau)(\beta_k-\alpha_k) \\
&\Large \tau^2=1-\tau\to\tau=\frac{\sqrt{5}-1}{2}=0.618
\end{align*}
$$
![image-20231226173058268](doc/image-20231226173058268.png)

另一种情况，计算结果是一样的，都是$\tau=\frac{\sqrt{5}-1}{2}$

#### 2.2.2.3 收敛率

拿$f(\lambda_k)>f(\mu_k), \ \to \alpha_{k+1}=\lambda_k, \ \beta_{k+1}= \beta_k$这种情况为例
$$
\begin{align*}
&\Large \beta_{k+1}-\alpha_{k+1}=\beta_k-[\alpha_k+(1-\tau)(\beta_k-\alpha_k)]=\tau(\beta_k-\alpha_k)\\
&\Large \frac{\beta_{k+1}-\alpha_{k+1}}{\beta_k-\alpha_k}=\tau\\
&\Large \beta_k-\alpha_k=\tau(\beta_{k-1}-\alpha_{k-1})=...=\tau^k(\beta_0-\alpha_0)<\epsilon\\
&\Large k\ge\ln_\tau\frac{\epsilon}{(\beta_0-\alpha_0)}
\end{align*}
$$
即，我们至少要进行k次才能收敛
