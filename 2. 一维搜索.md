# 1. 概念

一维搜索是在一个给定的函数f(x)中，寻找极值或者最值的过程

一般这种问题都是极值点很难直接获得的情况



# 2. 试探法

此方法是用在单峰函数上进行的，

## 2.1. 进退法

在一个多峰函数中，通过进退法确定波谷区间，在波谷区间里面搜索极小值点（最小值点）

**进退法**用来寻找波谷区间（注意这是一个函数的波谷，离散数据不能用这个方法）

![img](./doc\1703564654535-7e61fdac-b3d9-410b-9a43-8751084ddb86.png)

算法的思路

![img](./doc\1703565152292-e57e608b-447e-495e-b223-d0d5f04fcffc.png)

```python
#  确定单峰区间
def successFailMethod(x1, h, func):  # x1为初始位置，h为步进长度
    f1 = func(x1)
    x2 = x1 + h
    f2 = func(x2)
    if f2 < f1:
        while True:
            x3 = x2 + h
            f3 = func(x3)
            if f3 < f2:
                x2 = x3
                f2 = f3
            else:
                break
        return [x1, x3]
    else:
        while True:
            x3 = x1 - h
            f3 = func(x3)
            if f3 < f1:
                x1 = x3
                f1 = f3
            else:
                break
        return [x3, x2]
```

<img src="doc/1703567256190-0d16e372-ede5-426e-bd3f-f152fa5c2ddf-17035785013465.png" alt="img" style="zoom:50%;" />

<img src="https://cdn.nlark.com/yuque/0/2023/png/1606105/1703567313776-c197a679-fe37-4a07-bed5-ebc5576c1579.png" alt="img" style="zoom:50%;" />



## 2.2. 确定极小值点

已知多峰函数的单峰区间，或者单峰函数即可用**试探法**确定极小值点（最小值点）

基本思路是 ↓

在区间$[a_k, b_k]$， 尝试点为$\lambda_k$和$\mu_k$

![image-20231226163550950](doc/image-20231226163550950.png)

如果$f(\lambda_k)<f(\mu_k)$则极小值（最小值）一定在$[\alpha_k, \ \mu_k]$上，不可能在$[\mu_k, \ \beta_k]$上，则

我们更新边界：$f(\lambda_k)<f(\mu_k), \ \to \alpha_{k+1}=\alpha_k, \ \beta_{k+1}= \mu_k$

![image-20231226163634985](doc/image-20231226163634985.png)

如果$f(\lambda_k)>f(\mu_k)$则极小值（最小值）一定在$[\lambda_k, \ \beta_k]$上，不可能在$[\alpha_k, \ \mu_k]$上，则

我们更新边界：$f(\lambda_k)>f(\mu_k), \ \to \alpha_{k+1}=\lambda_k, \ \beta_{k+1}= \beta_k$

下面两个方法的共同目标是减少计算的次数，为了减少计算过程更新的，算法会利用上次计算的结果。

![image-20231226163550950](doc/image-20231226163550950.png)

在这个例子中，$\beta_{k+1} =\mu_k$, $\alpha_{k+1}=\alpha_k$,为了减少计算此时，可以让新的$\mu_{k+1}=\lambda_k$，$f(\mu_{k+1})=f(\lambda_k)$，如下图。

这样便可以减少一次计算，变成探索极值点是否在上图的$[\alpha_{k}, \ \lambda_k]$上

![image-20231226173058268](doc/image-20231226173058268.png)



两个算法的不同的点在于$\lambda_k、\beta_k$的计算方法，以及$\tau_k$的取值

判断是否收敛的依据是：当$|\mu_k-\lambda_k|<\epsilon$时，就认为已经收敛，取值为$[\lambda,k-\mu_k]$区间上的点



### 2.2.1. 黄金分割法

#### 2.2.1.1 基本方法

黄金分割法，试探点的计算方法为：$\lambda_k=\alpha_k+(1-\tau)(b_k - a_k)$，$u_k=\alpha_k+\tau(b_k-\alpha_k)$

为了实现这一点$\mu_{k+1}=\lambda_k$：
$$
\begin{align*}
&\Large \mu_{k+1}=\alpha_{k+1}+\tau(b_{k+1}-\alpha_{k+1})\\
&\Large 因为\alpha_{k+1}=\alpha_k,\beta_{k+1}=\mu_k\\
&\Large  \mu_{k+1}=\alpha_{k+1}+\tau(b_{k+1}-\alpha_{k+1})\\
&\Large \ \ \ \ \ \ \ \  =\alpha_k+\tau(\mu_k-\alpha_k)\\
&\Large \ \ \ \ \ \ \ \  = \alpha_k+\tau[a_k+\tau(\beta_k-\alpha_k)-\alpha_k]\\
&\Large \ \ \ \ \ \ \ \  =\alpha_k+\tau^2(\beta_k-\alpha_k)\\
&\Large \mu_{k+1}=\alpha_k+\tau^2(\beta_k-\alpha_k)=\lambda_k=\lambda_k+(1-\tau)(\beta_k-\alpha_k) \\
&\Large \tau^2=1-\tau\to\tau=\frac{\sqrt{5}-1}{2}=0.618
\end{align*}
$$

另一种情况，计算结果是一样的，都是$\tau=\frac{\sqrt{5}-1}{2}$

#### 2.2.1.收敛率

拿$f(\lambda_k)>f(\mu_k), \ \to \alpha_{k+1}=\lambda_k, \ \beta_{k+1}= \beta_k$这种情况为例
$$
\begin{align*}
&\Large \beta_{k+1}-\alpha_{k+1}=\beta_k-[\alpha_k+(1-\tau)(\beta_k-\alpha_k)]=\tau(\beta_k-\alpha_k)\\
&\Large \frac{\beta_{k+1}-\alpha_{k+1}}{\beta_k-\alpha_k}=\tau\\
&\Large \beta_k-\alpha_k=\tau(\beta_{k-1}-\alpha_{k-1})=...=\tau^k(\beta_0-\alpha_0)<\epsilon\\
&\Large k\ge\ln_\tau\frac{\epsilon}{(\beta_0-\alpha_0)}\to k=\lceil \ln_\tau\frac{\epsilon}{(\beta_0-\alpha_0)}\rceil
\end{align*}
$$


即，我们至少要进行k次才能收敛

```python
#  黄金分割法确定单峰区间内的极值点
def goldenSectionMethod(l, r, epsilon, func):
    """
    :param l: 区间左
    :param r: 区间右
    :param epsilon: 精度，r - l < epsilon时退出
    :param func: 函数
    :return: 返回极小值的x
    """
    num = 0
    tau = (np.sqrt(5) - 1) / 2
    original_R, original_L = r, l
    while r - l > epsilon:
        Lambda = l + (1 - tau) * (r - l)
        Mu = l + tau * (r - l)
        yLambda = func(Lambda)
        yMu = func(Mu)
        if yLambda < yMu:
            l = l
            r = Mu
        else:
            l = Lambda
            r = r
        num += 1
    return (r + l) / 2, np.ceil(np.log(epsilon / (original_R - original_L)) / np.log(tau)), num
```







### 2.2.2斐波那契数列法

#### 2.2.2.1 方法

​	此方法的探测点计算为：

**下面这个n是预设的，在求收敛率的时候会求n**

$\Large \lambda_k=\alpha_k+ \frac{F_{n-k-1}}{F_{n-k+1}}(\beta_k-\alpha_k), \ \mu_k=\alpha_k +\frac{F_{n-k}}{F_{n-k+1}}(\beta_k-\alpha_k)$

可以证明$\mu_{k+1}=\lambda_k$
$$
\begin{align*}
&\Large \mu_{k+1} =\alpha_{k+1} +\frac{F_{n-(k+1)}}{F_{n-(k+1) + 1}}(\beta_{k+1}-\alpha_{k+1}) \\
&\Large \ \ \ \ \ \ \ \  = \alpha_k+\frac{F_{n-k-1}}{F_{n-k}}(\mu_k-\alpha_k)\\
&\Large \ \ \ \ \ \ \ \  =  \alpha_k+\frac{F_{n-k-1}}{F_{n-k}}(\alpha_k +\frac{F_{n-k}}{F_{n-k+1}}(\beta_k-\alpha_k)-\alpha_k)\\
&\Large \ \ \ \ \ \ \ \  =  \alpha_k+\frac{F_{n-k-1}}{F_{F-k+1}}(\beta_k-\alpha_k)\\
&\Large \ \ \ \ \ \ \ \  =  \lambda_k
\end{align*}
$$

#### 2.2.2.2  收敛率

以$\alpha_{k+1} = \alpha_k$，$\beta_{k+1} = \mu_k$为例子
$$
\begin{align*}
&\Large \beta_{k+1}-\alpha_{k+1}= \mu_k - \alpha_k =[\alpha_k +\frac{F_{n-k}}{F_{n-k+1}}(\beta_k-\alpha_k)]-\alpha_k=\frac{F_{n-k}}{F_{n-k+1}}(\beta_k-\alpha_k)\\
&\Large \frac{\beta_{k+1}-\alpha_{k+1}}{\beta_k-\alpha_k}=\frac{F_{n-k}}{F_{n-k+1}}\\
&\Large k=1\to \beta_2-\alpha_2=\frac{F_{n-1}}{F_n}(\beta_1-\alpha_1)\\
&...\\
&\Large k=n-1\to \beta_n-\alpha_n=\frac{F_1}{F_2}(\beta_{n-1}-\alpha_{n-1})\\
&\Large \beta_n-\alpha_n=\frac{1}{F_n}(\beta_1-\alpha_1)<\epsilon\\
&\Large F_n> \frac{\beta_1-\alpha_1}{\epsilon}\to n
\end{align*}
$$


# 3. 函数逼近法



## 3.1 牛顿法

牛顿法求一维搜索最优问题，本质上是用一个函数对下凹的逼近

![image-20231226213312835](doc/image-20231226213312835.png)

不断更新这个函数的极值点，即可完成对目标函数的接近

这个函数的选择为目标函数的二次泰勒展开（无余项）第k次的展开点为$x_k$:
$$
\Large Q(x)=f(x_k)+f'(x_k)(x-x_k)+\frac{1}{2}f''(x)(x-x_k)^2
$$
$Q(x)$的极值点为：
$$
\begin{align*}
& \Large Q'(x)=f'(x_k)+f''(x_k)(x-x_k)=0\\
&\Large x=x_k-\frac{f'(x_k)}{f''(x_k)}
\end{align*}
$$
随机选取一个点，作为展开点，即可

判断收敛的依据可以是：$|f'(x_k)| < \epsilon$

但这个方法有一个问题就是，如果没有惩罚项，在多峰函数中会随机收敛于一个极值

比如：函数$y=0.25 * x^4+\frac{4}{3}*x^3+1.5*x^2$

初始值设为2，$x_1=2-\frac{y'(2)}{y''(2)}=0$，直接收敛于x=0

![image-20231226223937757](doc/image-20231226223937757.png)









